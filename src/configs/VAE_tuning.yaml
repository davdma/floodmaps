seed: 9290
save: False
save_path:

data:
    size: 64
    samples: 500
    kernel_size: 5
    use_lee: False
    random_flip: True

model:
    autodespeckler: VAE # ['CNN1', 'CNN2', 'DAE', 'VAE']
    cnn1:
        latent_dim:
        AD_dropout:
        AD_activation_func:
    cnn2:
        AD_num_layers:
        AD_kernel_size:
        AD_dropout:
        AD_activation_func:
    dae:
        AD_num_layers:
        AD_kernel_size:
        AD_dropout:
        AD_activation_func:
        noise_type:
        noise_coeff:
    vae:
        latent_dim: 200
        VAE_beta: 1.0
        beta_annealing: True
        beta_period: 50
        beta_cycles: 4
        beta_proportion: 0.5
    
train:
    epochs: 400
    batch_size: 1024
    loss: L1Loss # ['L1Loss', 'MSELoss', 'PseudoHuberLoss', 'HuberLoss', 'LogCoshLoss', 'JSDLoss']
    clip: 1.0
    lr: 0.0001
    optimizer: Adam # ['Adam', 'SGD']
    LR_scheduler: Constant # ['Constant', 'ReduceLROnPlateau', 'CosAnnealingLR']
    LR_patience: 5
    LR_T_max: 200
    early_stopping: True
    patience: 15
    subset: 1.0
    num_workers: 10

eval:
    mode: val # ['val', 'test'],
    
wandb:
    project: SAR_AD_Tuning_Head_2
    group:
    num_sample_predictions: 40

logging:
    grad_norm_freq: 10
