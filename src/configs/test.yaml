seed: 831002
save: False
save_path:

data:
    size: 64
    samples: 500
    kernel_size: 5
    use_lee: False
    random_flip: True

model:
    autodespeckler: CNN1 # ['CNN1', 'CNN2', 'DAE', 'VAE']
    cnn1:
        latent_dim: 1024
        AD_dropout: 0.05
        AD_activation_func: leaky_relu # ['leaky_relu', 'relu', 'softplus', 'mish', 'gelu', 'elu']
    cnn2:
        AD_num_layers: 5
        AD_kernel_size: 3
        AD_dropout: 0.1
        AD_activation_func: leaky_relu # ['leaky_relu', 'relu', 'softplus', 'mish', 'gelu', 'elu']
    dae:
        AD_num_layers: 5
        AD_kernel_size: 3
        AD_dropout: 0.1
        AD_activation_func: leaky_relu # ['leaky_relu', 'relu', 'softplus', 'mish', 'gelu', 'elu']
        noise_type: log_gamma # ['normal', 'masking', 'log_gamma']
        noise_coeff: 0.1
    vae:
        latent_dim: 512
        VAE_beta: 1.0
        beta_annealing: True
        beta_period: 5
        beta_cycles: 2
        beta_proportion: 0.5
    
train:
    epochs: 200
    batch_size: 16384
    loss: L1Loss # ['L1Loss', 'MSELoss', 'PseudoHuberLoss', 'HuberLoss', 'LogCoshLoss', 'JSDLoss']
    clip: 1.0
    lr: 0.0001
    optimizer: Adam # ['Adam', 'SGD']
    LR_scheduler: Constant # ['Constant', 'ReduceLROnPlateau', 'CosAnnealingLR']
    LR_patience:
    LR_T_max:
    early_stopping: True
    patience: 10
    subset: 1.0
    num_workers: 4

eval:
    mode: val # ['val', 'test'],

wandb:
    project: debug
    group:
    num_sample_predictions: 40

logging:
    grad_norm_freq: 10
